<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>9. Signals, Sampling &amp; Filtering</title>
<!-- 2015-05-14 Thu 11:15 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Paul Gribble" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet"
                         href="mystyle.css"
                         type="text/css"/><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create', 'UA-52544521-1', 'auto');ga('send', 'pageview');</script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="index.html"> UP </a>
 |
 <a accesskey="H" href="index.html"> HOME </a>
</div><div id="content">
<h1 class="title">9. Signals, Sampling &amp; Filtering</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Time domain representation of signals</a></li>
<li><a href="#sec-2">2. Frequency domain representation of signals</a></li>
<li><a href="#sec-3">3. Fast Fourier transform (FFT)</a></li>
<li><a href="#sec-4">4. Sampling</a></li>
<li><a href="#sec-5">5. Power spectra</a></li>
<li><a href="#sec-6">6. Power Spectral Density</a></li>
<li><a href="#sec-7">7. Decibel scale</a></li>
<li><a href="#sec-8">8. Spectrogram</a></li>
<li><a href="#sec-9">9. Inverse Fast Fourier transform (IFFT)</a></li>
<li><a href="#sec-10">10. Filtering</a></li>
<li><a href="#sec-11">11. Quantization</a></li>
<li><a href="#sec-12">12. Sources of noise</a></li>
<li><a href="#sec-13">13. Exercises</a></li>
</ul>
</div>
</div>
<hr  />

<p>
Whereas signals in nature (such as sound waves, magnetic fields, hand
position, electromyograms (EMG), electroencephalograms (EEG),
extra-cellular potentials, etc) vary continuously, often in science we
measure these signals by <b>sampling</b> them repeatedly over time, at some
<b>sampling frequency</b>. The resulting collection of measurements is a
<b>discretized</b> representation of the original continuous signal.
</p>

<p>
Before we get into <b>sampling theory</b> however we should first talk
about how signals can be represented both in the <b>time domain</b> and in
the <b>frequency domain</b>.
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Time domain representation of signals</h2>
<div class="outline-text-2" id="text-1">
<p>
This is how you are probably used to thinking about signals, namely how the magnitude of a signal varies over time. So for example a signal \(s\) containing a sinusoid with a period \(T\) of 0.5 seconds (a frequency of 2 Hz) and a peak-to-peak magnitude \(b\) of 2 volts is represented in the time domain \(t\) as:
</p>

\begin{equation}
s(t) = \left(\frac{b}{2}\right) \mathrm{sin}\left(wt\right)
\end{equation}

<p>
where
</p>

\begin{equation}
w = \frac{2 \pi}{T}
\end{equation}

<p>
We can visualize the signal by plotting its magnitude as a function of time:
</p>


<div class="figure">
<p><img src="code/signal_timedomain.jpg" alt="signal_timedomain.jpg" width="400" />
</p>
</div>
</div>
</div>


<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Frequency domain representation of signals</h2>
<div class="outline-text-2" id="text-2">
<p>
We can also represent signals in the frequency domain. This requires
some understanding of the <a href="http://en.wikipedia.org/wiki/Fourier_series">Fourier series</a>. The idea of the Fourier
series is that all periodic signals can be represented by (decomposed
into) the sum of a set of pure sines and cosines that differ in
frequency and period. See the wikipedia link for lots of details and a
helpful animation.
</p>

\begin{equation}
s(t) = \frac{a_{0}}{2} + \sum_{n=1}^{\infty} \left[a_{n}\mathrm{cos}(nwt) + b_{n}\mathrm{sin}(nwt)\right]
\end{equation}

<p>
The coefficients \(a_{n}\) and \(b_{n}\) define the weighting of the different sines and cosines at different frequencies. In other words these coefficients represent the strength of the different frequency components in the signal.
</p>

<p>
We can also represent the Fourier series using only sines:
</p>

\begin{equation}
s(t) = \frac{a_{0}}{2} \sum_{n=1}^{\infty} \left[r_{n}\mathrm{cos}(nwt-\phi_{n})\right]
\end{equation}

<p>
Using this formulation we now have <b>magnitude</b> coefficients \(r_{n}\)
and <b>phase</b> coefficients \(\phi_{n}\). That is, we are representing the
original signal \(s(t)\) using a sum of sinusoids of different
frequencies and phases.
</p>

<p>
Here is a java applet that lets you play with how sines and cosines
can be used to represent different signals: <a href="http://www.falstad.com/fourier/">Fourier Series Applet</a>.
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> Fast Fourier transform (FFT)</h2>
<div class="outline-text-2" id="text-3">
<p>
Given a signal there is a very efficient computational algorithm
called the <a href="http://en.wikipedia.org/wiki/Fast_Fourier_transform">Fast Fourier transform</a> (FFT) for computing the magnitude
and phase coefficients. We will not go into the details of this
algorithm here, most high level programming languages have a library
that includes the FFT algorithm.
</p>

<p>
Here is a video showing a 100-year-old mechanical computer that does
both forward and inverse Fourier transforms:
</p>

<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=NAsM30MAHLg">Harmonic Analyzer (1/4)</a>
</li>
<li><a href="https://www.youtube.com/watch?v=8KmVDxkia_w">Harmonic Analyzer (2/4)</a>
</li>
<li><a href="https://www.youtube.com/watch?v=6dW6VYXp9HM">Harmonic Analyzer (3/4)</a>
</li>
<li><a href="https://www.youtube.com/watch?v=jfH-NbsmvD4">Harmonic Analyzer (4/4)</a>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Sampling</h2>
<div class="outline-text-2" id="text-4">
<p>
Before we talk about the FFT and magnitude and phase coefficients, we need to
talk about discrete versus continuous signals, and sampling. In theory we can
derive a mathematical description of the Fourier decomposition of a continuous
signal, as we have done above, in terms of an infinite number of sinusoids. In
practice however, signals are not continuous, but are <b>sampled</b> at some
discrete <b>sampling rate</b>.
</p>

<p>
For example, when we use Optotrak to record the position of the fingertip during pointing experiments, we choose a sampling rate of 200 Hz. This means 200 times per second the measurement instrument samples and records the position of the fingertip. The interval between any two samples is 5 ms. It turns out that the sampling rate used has a specific effect on the number of frequencies used in a discrete Fourier representation of the recorded signals.
</p>

<p>
The <a href="http://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Shannon-Nyquist sampling theorem</a> states that a signal must be sampled at a rate which is at least twice that of its highest frequency component. If a signal contains power at frequencies higher than half the sampling rate, these high frequency components will appear in the sampled data at lower frequencies and will distort the recording. This is known as the problem of
<a href="http://en.wikipedia.org/wiki/Aliasing">aliasing</a>.
</p>

<p>
Let's look at a concrete example that will illustrate this concept. Let's
assume we have a signal that we want to sample, and we choose a sampling rate
of 4 Hz. This means every 250 ms we sample the signal. According to the
Shannon-Nyquist theorem, the maximum frequency we can uniquely identify is half
that, which is 2 Hz. This is called the <a href="http://en.wikipedia.org/wiki/Nyquist_frequency">nyquist frequency</a>. Let's look at
a plot and see why this is so.
</p>

<p>
Below we see a solid blue line showing a 2 Hz signal, a magenta dashed line showing a 4 Hz signal, and a green dashed line showing a 8 Hz signal. Now imagine we sample these signals at 2 Hz, indicated by the vertical red lines. Notice that at the sample points (vertical red lines), the 2 Hz, 4 Hz and 8 Hz signals overlap with identical values. This means that on the basis of our 2 Hz samples, we cannot distinguish between frequencies of 2, 4 and 8 Hz. What's more, what this means is that if the signal we are actually sampling at 2 Hz has significant signal power at frequencies above the Nyquist (1 Hz) then the power at these higher frequencies will influence our estimates of the magnitude coefficients corresponding to frequencies below the Nyquist&#x2026; in other words the high-frequency power will be aliased into the lower frequency estimates.
</p>


<div class="figure">
<p><img src="code/signal_aliasing.jpg" alt="signal_aliasing.jpg" width="600" />
</p>
</div>

<p>
Below is another example taken from the <a href="http://en.wikipedia.org/wiki/Aliasing">wikipedia article on aliasing</a>. Here we have two sinusoids &#x2014; one at 0.1 Hz (blue) and another at 0.9 Hz (red). We sample both at a sampling rate of 1 Hz (vertical green lines). You can see that at the sample points, both the 0.1 Hz and 0.9 Hz sinusoids "hit" the sample points and thus both would influence our estimates of the power at the 0.1 Hz frequency. Since the sampling rate is 1 Hz, the Nyquist frequency (the maximum frequency we can distinguish) is 0.5 Hz &#x2026; and so any power in the signal above 0.5 Hz (such as 0.9 Hz) will be aliased down into the lower frequencies (in this case into the 0.1 Hz band).
</p>


<div class="figure">
<p><img src="code/signal_aliasingsines.jpg" alt="signal_aliasingsines.jpg" width="600" />
</p>
</div>

<p>
So the message here is that in advance, before choosing your sampling rate, you should have some knowledge about the highest frequency that you (a) are interested in identifying; and (b) you think is a real component in the signal (as opposed to random noise). In cases where you have no a priori knowledge about the expected frequency content, one strategy is to remove high frequency components <i>before sampling</i>. This can be accomplished using low-pass filtering &#x2014; sometimes called anti-aliasing filters. Once the signal has been sampled, it's too late to perform anti-aliasing.
</p>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> Power spectra</h2>
<div class="outline-text-2" id="text-5">
<p>
Having bypassed completely the computational details of how magnitude and phase coefficients are estimated, we will now talk about how to interpret them.
</p>

<p>
For a given signal, the collection of magnitude coefficients gives a description of the signal in terms of the strength of the various underlying frequency components. For our immediate purposes these magnitude coefficients will be most important to us and we can for the moment set aside the phase coefficients.
</p>

<p>
Here is an example of a power spectrum for a pure 10 Hz signal, sampled at 100 Hz.
</p>


<div class="figure">
<p><img src="code/signal_spectrum10.jpg" alt="signal_spectrum10.jpg" width="600" />
</p>
</div>

<p>
The magnitude values are zero for every frequency except 10 Hz. We haven't plotted the phase coefficients. The set of magnitude and phase coefficients derived from a Fourier analysis is a complete description of the underlying signal, with one caveat &#x2014; only frequencies up to the Nyquist are represented. So the idea here is that one can go between the original time-domain representation of the signal and this frequency domain  representation of the signal without losing information. As we shall see below in the section on filtering, we can perform operations in the frequency domain and then transform back into the time domain. 
</p>

<p>
Here is some Python code to illustrate these concepts. We construct a one second signal sampled at 1000 Hz that is composed of a 6 Hz, 10 Hz nad 13 Hz component. We then use the <code>fft()</code> function to compute the Fast Fourier transform, we extract the magnitude information, we set our frequency range (up to the Nyquist) and we plot the <b>spectrum</b>:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #b22222;"># </span><span style="color: #b22222;">construct signal and plot in the time domain</span>
figure(figsize=(6,12))
<span style="color: #a0522d;">t</span> = linspace(0, 1, 1001)
<span style="color: #a0522d;">y</span> = sin(2*pi*t*6) + sin(2*pi*t*10) + sin(2*pi*t*13)
subplot(311)
plot(t, y, <span style="color: #8b2252;">'b-'</span>)
xlabel(<span style="color: #8b2252;">"TIME (sec)"</span>)
ylabel(<span style="color: #8b2252;">"SIGNAL MAGNITUDE"</span>)
<span style="color: #b22222;"># </span><span style="color: #b22222;">compute FFT and plot the magnitude spectrum</span>
<span style="color: #a0522d;">F</span> = fft(y)
<span style="color: #a0522d;">N</span> = <span style="color: #483d8b;">len</span>(t)             <span style="color: #b22222;"># </span><span style="color: #b22222;">number of samples</span>
<span style="color: #a0522d;">dt</span> = 0.001             <span style="color: #b22222;"># </span><span style="color: #b22222;">inter-sample time difference</span>
<span style="color: #a0522d;">w</span> = fftfreq(N, dt)     <span style="color: #b22222;"># </span><span style="color: #b22222;">gives us a list of frequencies for the FFT</span>
<span style="color: #a0522d;">ipos</span> = where(w&gt;0)
<span style="color: #a0522d;">freqs</span> = w[ipos]        <span style="color: #b22222;"># </span><span style="color: #b22222;">only look at positive frequencies</span>
<span style="color: #a0522d;">mags</span> = <span style="color: #483d8b;">abs</span>(F[ipos])    <span style="color: #b22222;"># </span><span style="color: #b22222;">magnitude spectrum</span>
subplot(312)
plot(freqs, mags, <span style="color: #8b2252;">'b-'</span>)
ylabel(<span style="color: #8b2252;">"POWER"</span>)
subplot(313)
plot(freqs, mags, <span style="color: #8b2252;">'b-'</span>)
xlim([0, 50])          <span style="color: #b22222;"># </span><span style="color: #b22222;">replot but zoom in on freqs 0-50 Hz</span>
ylabel(<span style="color: #8b2252;">"POWER"</span>)
xlabel(<span style="color: #8b2252;">"FREQUENCY (Hz)"</span>)
savefig(<span style="color: #8b2252;">"signal_3freqs.jpg"</span>, dpi=150)
</pre>
</div>


<div class="figure">
<p><img src="code/signal_3freqs.jpg" alt="signal_3freqs.jpg" height="600" />
</p>
</div>

<p>
We can see that the power spectrum has revealed peaks at 6, 10 and 13 Hz&#x2026; which we know is correct, since we designed our signal from scratch.
</p>

<p>
Typically however signals in the real world that we record are not pure sinusoids, but contain random noise. Noise can originate from the actual underlying process that we are interested in measuring, and it can also originate from the instruments we use to measure the signal. For noisy signals, the FFT taken across the whole signal can be noisy as well, and can make it difficult to see peaks.
</p>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Power Spectral Density</h2>
<div class="outline-text-2" id="text-6">
<p>
One solution is instead of performing the FFT on the entire signal all at once, to instead, split the signal into chunks, take the FFT of each chunk, and then average these spectra to come up with a smoother spectrum. This can be accomplished using a <a href="http://www.mathworks.com/help/signal/ref/dspdata.psd.html">power spectral density</a> function. In SciPy (and in MATLAB) there is a function <code>psd()</code> to accomplish this. We won't go into the mathematical details or the theoretical considerations (relating to stochastic processes) but for now suffice it to say that the psd can often give you a better estimate of the power at different frequencies compared to a "plain" FFT.
</p>

<p>
Here is an example of plotting the power spectral density of a signal in Python / SciPy. We construct a 50 Hz signal at 200 Hz sampling rate, and we add some random noise on top:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #b22222;"># </span><span style="color: #b22222;">construct signal and plot in the time domain</span>
figure(figsize=(6,8))
<span style="color: #a0522d;">t</span> = linspace(0, 1, 201)
<span style="color: #a0522d;">y</span> = sin(2*pi*t*50) + randn(<span style="color: #483d8b;">len</span>(t))/2
subplot(211)
plot(t, y, <span style="color: #8b2252;">'b-'</span>)
xlabel(<span style="color: #8b2252;">"TIME (sec)"</span>)
ylabel(<span style="color: #8b2252;">"SIGNAL MAGNITUDE"</span>)
<span style="color: #b22222;"># </span><span style="color: #b22222;">compute and plot the power spectral density</span>
subplot(212)
psd(y, Fs=200)
savefig(<span style="color: #8b2252;">"signal_50_psd.jpg"</span>, dpi=150)
</pre>
</div>


<div class="figure">
<p><img src="code/signal_50_psd.jpg" alt="signal_50_psd.jpg" height="600" />
</p>
</div>

<p>
You can see that the peak at 50 Hz stands nicely above all the noise, about 20 dB above the noise, in fact (-20 dB corresponds to 1/10th the power, see below).
</p>

<p>
We have been ignoring the <b>phase</b> of the signal here, but just like the magnitude coefficients over frequencies, we can recover the phase coefficients of the signal as well.
</p>
</div>
</div>

<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> Decibel scale</h2>
<div class="outline-text-2" id="text-7">
<p>
The decibel (dB) scale is a ratio scale. It is commonly used to measure sound
level but is also widely used in electronics and signal processing. The dB is a
logarithmic unit used to describe a ratio. You will often see power spectra displayed in units of decibels.
</p>

<p>
The difference between two sound levels (or two power levels, as in the case of
the power spectra above), is defined to be:
</p>

\begin{equation}
20 log_{10}\frac{P_{2}}{P_{1}} dB
\end{equation}

<p>
Thus when \(P_{2}\) is twice as large as \(P_{1}\), then the difference is about
6 dB. When \(P_{2}\) is 10 times as large as \(P_{1}\), the difference is 20 dB. A
100 times difference is 40 dB.
</p>

<p>
An advantage of using the dB scale is that it is easier to see small signal
components in the presence of large ones. In other words large components don't
visually swamp small ones.
</p>

<p>
Since the dB scale is a ratio scale, to compute absolute levels one needs a
reference &#x2014; a zero point. In acoustics this reference is usually 20
micropascals &#x2014; about the limit of sensitivity of the human ear.
</p>

<p>
For our purposes in the absence of a meaningful reference we can use 1.0 as the
reference (i.e. as \(P_{1}\) in the above equation).
</p>
</div>
</div>

<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> Spectrogram</h2>
<div class="outline-text-2" id="text-8">
<p>
Often there are times when you may want to examine how the power spectrum of a signal (in other words its frequency content) changes over time. In speech acoustics for example, at certain frequencies, bands of energy called <a href="http://en.wikipedia.org/wiki/Formant">formants</a> may be identified, and are associated with certain speech sounds like vowels and vowel transitions. It is thought that the neural systems for human speech recognition are tuned for identification of these formants.
</p>

<p>
Essentially a spectrogram is a way to visualize a series of power spectra computed from slices of a signal over time. Imagine a series of single power spectra (frequency versus power) repeated over time and stacked next to each other over a time axis.
</p>

<p>
MATLAB has a built-in function called <code>specgram()</code> that will generate a spectrogram. There is also a nice demo which can be called up with the command <code>specgramdemo</code>. MATLAB has a sample audio file called <code>mtlb.mat</code> which can be loaded from the command line:
</p>

<div class="org-src-container">

<pre class="src src-octave">load mtlb
figure
specgram(mtlb<span style="color: #483d8b;">,</span>256<span style="color: #483d8b;">,</span>Fs<span style="color: #483d8b;">,</span>256<span style="color: #483d8b;">,</span>230)
sound(mtlb)
</pre>
</div>


<div class="figure">
<p><img src="code/signal_specgram.jpg" alt="signal_specgram.jpg" width="400" />
</p>
</div>
</div>
</div>

<div id="outline-container-sec-9" class="outline-2">
<h2 id="sec-9"><span class="section-number-2">9</span> Inverse Fast Fourier transform (IFFT)</h2>
<div class="outline-text-2" id="text-9">
<p>
Once we have the FFT of a signal, which represents the signal in the frequency domain as a series of magnitude and phase coefficients, we can reconstruct the signal in the time-domain using the inverse fast fourier transform (IFFT). Here is a concrete example:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #b22222;"># </span><span style="color: #b22222;">construct signal and plot in the time domain</span>
figure(figsize=(6,12))
<span style="color: #a0522d;">t</span> = linspace(0, 1, 1001)
<span style="color: #a0522d;">y</span> = sin(2*pi*t*6) + sin(2*pi*t*10) + sin(2*pi*t*13)
subplot(411)
plot(t, y, <span style="color: #8b2252;">'b-'</span>)
xlabel(<span style="color: #8b2252;">"TIME (sec)"</span>)
ylabel(<span style="color: #8b2252;">"ORIGINAL SIGNAL"</span>)
<span style="color: #b22222;"># </span><span style="color: #b22222;">compute FFT and plot the magnitude spectrum</span>
<span style="color: #a0522d;">F</span> = fft(y)
<span style="color: #a0522d;">N</span> = <span style="color: #483d8b;">len</span>(t)             <span style="color: #b22222;"># </span><span style="color: #b22222;">number of samples</span>
<span style="color: #a0522d;">dt</span> = 0.001             <span style="color: #b22222;"># </span><span style="color: #b22222;">inter-sample time difference</span>
<span style="color: #a0522d;">w</span> = fftfreq(N, dt)     <span style="color: #b22222;"># </span><span style="color: #b22222;">gives us a list of frequencies for the FFT</span>
<span style="color: #a0522d;">ipos</span> = where(w&gt;0)
<span style="color: #a0522d;">freqs</span> = w[ipos]        <span style="color: #b22222;"># </span><span style="color: #b22222;">only look at positive frequencies</span>
<span style="color: #a0522d;">mags</span> = <span style="color: #483d8b;">abs</span>(F[ipos])    <span style="color: #b22222;"># </span><span style="color: #b22222;">magnitude component</span>
<span style="color: #a0522d;">phase</span> = imag(F[ipos])  <span style="color: #b22222;"># </span><span style="color: #b22222;">phase component</span>
subplot(412)
plot(freqs, mags, <span style="color: #8b2252;">'b-'</span>)
xlim([0, 50])          <span style="color: #b22222;"># </span><span style="color: #b22222;">replot but zoom in on freqs 0-50 Hz</span>
ylabel(<span style="color: #8b2252;">"FFT MAGNITUDE"</span>)
xlabel(<span style="color: #8b2252;">"FREQUENCY (Hz)"</span>)
subplot(413)
plot(freqs, phase, <span style="color: #8b2252;">'b-'</span>)
xlim([0, 50])          <span style="color: #b22222;"># </span><span style="color: #b22222;">replot but zoom in on freqs 0-50 Hz</span>
ylabel(<span style="color: #8b2252;">"FFT PHASE"</span>)
xlabel(<span style="color: #8b2252;">"FREQUENCY (Hz)"</span>)
subplot(414)
<span style="color: #a0522d;">yr</span> = ifft(F)
plot(t, y, <span style="color: #8b2252;">'b-'</span>)
plot(t, yr, <span style="color: #8b2252;">'r-'</span>)
legend((<span style="color: #8b2252;">"original"</span>,<span style="color: #8b2252;">"reconstructed"</span>))
xlabel(<span style="color: #8b2252;">"TIME (sec)"</span>)
ylabel(<span style="color: #8b2252;">"RECONSTRUCTED SIGNAL"</span>)
savefig(<span style="color: #8b2252;">"signal_3freqs_ifft.jpg"</span>, dpi=150)
</pre>
</div>


<div class="figure">
<p><img src="code/signal_3freqs_ifft.jpg" alt="signal_3freqs_ifft.jpg" height="600" />
</p>
</div>

<p>
You can see above that the original signal is reconstructed in its entirety, simply on the basis of its frequency domain representation (the FFT).
</p>
</div>
</div>

<div id="outline-container-sec-10" class="outline-2">
<h2 id="sec-10"><span class="section-number-2">10</span> Filtering</h2>
<div class="outline-text-2" id="text-10">
<p>
We can use this property of signals to filter them. Below I take our original signal containing frequency components at 6, 10 and 13 Hz, I take the FFT, and then I set the values in the FFT corresponding to the frequency peaks of 10 and 13 Hz, to zero (and I leave the value corresponding to the frequency of 6 Hz unchanged). I then reconstruct a signal based on this altered frequency domain representation, using <code>ifft()</code>, and plot the resulting signal. What you can see is that by setting the coefficients corresponding to 10 and 13 Hz to zero, I essentially <b>filtered out</b> all of the power in the signal at those frequencies. The reconstructed signal now only has power at 6 Hz (the red line, it looks like a pure 6 Hz sinusoid).
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #b22222;"># </span><span style="color: #b22222;">construct signal and plot in the time domain</span>
figure(figsize=(6,12))
<span style="color: #a0522d;">t</span> = linspace(0, 1, 1001)
<span style="color: #a0522d;">y</span> = sin(2*pi*t*6) + sin(2*pi*t*10) + sin(2*pi*t*13)
subplot(311)
plot(t, y, <span style="color: #8b2252;">'b-'</span>)
xlabel(<span style="color: #8b2252;">"TIME (sec)"</span>)
ylabel(<span style="color: #8b2252;">"ORIGINAL SIGNAL"</span>)
<span style="color: #b22222;"># </span><span style="color: #b22222;">compute FFT and plot the magnitude spectrum</span>
<span style="color: #a0522d;">F</span> = fft(y)
<span style="color: #a0522d;">N</span> = <span style="color: #483d8b;">len</span>(t)             <span style="color: #b22222;"># </span><span style="color: #b22222;">number of samples</span>
<span style="color: #a0522d;">dt</span> = 0.001             <span style="color: #b22222;"># </span><span style="color: #b22222;">inter-sample time difference</span>
<span style="color: #a0522d;">w</span> = fftfreq(N, dt)     <span style="color: #b22222;"># </span><span style="color: #b22222;">gives us a list of frequencies for the FFT</span>
<span style="color: #a0522d;">ipos</span> = where(w&gt;0)
<span style="color: #a0522d;">freqs</span> = w[ipos]        <span style="color: #b22222;"># </span><span style="color: #b22222;">only look at positive frequencies</span>
<span style="color: #a0522d;">mags</span> = <span style="color: #483d8b;">abs</span>(F[ipos])    <span style="color: #b22222;"># </span><span style="color: #b22222;">magnitude component</span>
<span style="color: #a0522d;">phase</span> = imag(F[ipos])  <span style="color: #b22222;"># </span><span style="color: #b22222;">phase component</span>
<span style="color: #a0522d;">ip</span> = where(F&gt;5)[0]     <span style="color: #b22222;"># </span><span style="color: #b22222;">find peaks in FFT</span>
<span style="color: #a0522d;">Fs</span> = copy(F)           <span style="color: #b22222;"># </span><span style="color: #b22222;">make a copy of the signal FFT</span>
Fs[ip[[2,3]]] = 0      <span style="color: #b22222;"># </span><span style="color: #b22222;">set peaks corresponding to </span>
<span style="color: #a0522d;">yf</span> = ifft(Fs)          <span style="color: #b22222;"># </span><span style="color: #b22222;">reconstruct</span>
<span style="color: #a0522d;">ip</span> = where(F&gt;5)[0]     <span style="color: #b22222;"># </span><span style="color: #b22222;">find peaks in FFT</span>
<span style="color: #a0522d;">Ff</span> = copy(F)           <span style="color: #b22222;"># </span><span style="color: #b22222;">make a copy of the signal FFT</span>
Ff[ip[[1,2,3,4]]] = 0  <span style="color: #b22222;"># </span><span style="color: #b22222;">set 10Hz and 13Hz peaks to zero</span>
<span style="color: #a0522d;">magsf</span> = <span style="color: #483d8b;">abs</span>(Ff[ipos])  <span style="color: #b22222;"># </span><span style="color: #b22222;">magnitude component</span>
<span style="color: #a0522d;">phasef</span> = imag(Ff[ipos])<span style="color: #b22222;"># </span><span style="color: #b22222;">phase component</span>
<span style="color: #a0522d;">yf</span> = ifft(Ff)          <span style="color: #b22222;"># </span><span style="color: #b22222;">reconstruct</span>
subplot(312)
plot(freqs, mags, <span style="color: #8b2252;">'b-'</span>)
plot(freqs, magsf, <span style="color: #8b2252;">'r-'</span>, linewidth=2)
legend((<span style="color: #8b2252;">"original"</span>,<span style="color: #8b2252;">"filtered"</span>))
xlim([0, 50])          <span style="color: #b22222;"># </span><span style="color: #b22222;">replot but zoom in on freqs 0-50 Hz</span>
ylabel(<span style="color: #8b2252;">"FFT MAGNITUDE"</span>)
xlabel(<span style="color: #8b2252;">"FREQUENCY (Hz)"</span>)
subplot(313)
<span style="color: #a0522d;">yr</span> = ifft(F)
plot(t, y, <span style="color: #8b2252;">'b-'</span>)
plot(t, yf, <span style="color: #8b2252;">'r-'</span>,linewidth=2)
legend((<span style="color: #8b2252;">"original"</span>,<span style="color: #8b2252;">"filtered"</span>))
xlabel(<span style="color: #8b2252;">"TIME (sec)"</span>)
ylabel(<span style="color: #8b2252;">"RECONSTRUCTED SIGNAL"</span>)
savefig(<span style="color: #8b2252;">"signal_3freqs_filt.jpg"</span>, dpi=150)
</pre>
</div>


<div class="figure">
<p><img src="code/signal_3freqs_filt.jpg" alt="signal_3freqs_filt.jpg" height="600" />
</p>
</div>

<p>
This is an extremely simple minded way of filtering a signal, but it illustrates the underlying concepts. There are an entire range of algorithms for filtering that are designed to manipulate frequency ranges, and they differ in a number of respects including how quickly they alter the frequencies in question, how they affect the phase information in the signal, and a number of other things we won't go into here. There are entire signal processing textbooks oriented around this topic, so if you're interested in details, I can point you towards some good sources.
</p>

<p>
Here is a short summary of different kinds of filters, and some terminology.
</p>

<ul class="org-ul">
<li><b>low-pass filters</b> pass low frequencies without change, but attenuate (i.e. reduce) frequencies above the <b>cutoff frequency</b>
</li>
<li><b>high-pass filters</b> pass high frequencies and attenuate low frequencies, below the cutoff frequency
</li>
<li><b>band-pass filters</b> pass frequencies within a <b>pass band</b> frequency range and attenuate all others
</li>
<li><b>band-stop filters</b> (sometimes called <b>band-reject filters</b> or <b>notch filters</b>) attenuate frequencies within the <b>stop band</b> and pass all others
</li>
</ul>
</div>

<div id="outline-container-sec-10-1" class="outline-3">
<h3 id="sec-10-1"><span class="section-number-3">10.1</span> Characterizing filter performance</h3>
<div class="outline-text-3" id="text-10-1">
<p>
A useful way of characterizing a filter's performance is in terms of the ratio
of the amplitude of the output to the input (the amplitude ratio AR or gain),
and the phase shift (\(\phi\)) between the input and output, as functions of
frequency. A plot of the amplitude ratio and phase shift against frequency is
called a <a href="http://en.wikipedia.org/wiki/Bode_plot">Bode plot</a>.
</p>

<p>
The <b>pass band</b> of a filter is the range of frequencies over which signals
pass with no change. The <b>stop band</b> refers to the range of frequencies
over which a filter attenuates signals. The <b>cutoff frequency</b> or
<b>corner frequency</b> of a filter is used to describe the transition point
from the pass band to the reject band. This this transition cannot occur
instantaneously it is usually defined to be the point at which the filter
output is equal to -6 dB of the input in the pass band. The cutoff frequency is
sometimes called the -6 dB point or the half-power point since -6 dB
corresponds to half the signal power. The <b>roll-off</b> refers to the rate at
which the filter attenuates the input after the cutoff point. When the roll-off
is linear it can be specified as a specific slope, e.g. in terms of dB/decade
or dB/octave (an octave is a doubling in frequency).
</p>

<p>
Let's look at some examples of filter characteristics.
</p>


<div class="figure">
<p><img src="code/signal_bode.jpg" alt="signal_bode.jpg" width="400" />
</p>
</div>

<p>
Here the blue trace shows the power spectrum for the unfiltered signal. The red
trace shows a lowpass-filtered version of the signal with a cutoff frequency of
30 Hz. The green trace shows a low-pass with a cutoff frequency of 130 Hz. Also
notice that the roll-off of the 30 Hz lowpass is not as great as for the 130 Hz
lowpass, which has a higher roll-off.
</p>

<p>
Here are the corresponding signals shown in the time-domain:
</p>


<div class="figure">
<p><img src="code/signal_bodetime.jpg" alt="signal_bodetime.jpg" height="600" />
</p>
</div>

<p>
So we see a very good example of how low-pass filtering can be used very
effectively to filter out random noise. Key is the appropriate choice of
cut-off frequency.
</p>
</div>
</div>

<div id="outline-container-sec-10-2" class="outline-3">
<h3 id="sec-10-2"><span class="section-number-3">10.2</span> Common Filters</h3>
<div class="outline-text-3" id="text-10-2">
<p>
There are many different designs of filters, each with their own
characteristics (gain, phase and delay characteristics). Some common types:
</p>

<ul class="org-ul">
<li><b>Butterworth Filters</b> have frequency responses which are maximally flat and have a monotonic roll-off. They are well behaved and this makes them very popular choices for simple filtering applications. For example in my work I use them exlusively for filtering physiological signals. MATLAB has a built-in function called <code>butter()</code> that implements the butterworth filter.
</li>

<li><b>Tschebyschev Filters</b> provide a steeper monotonic roll-off, but at the expense of some ripple (oscillatory noise) in the pass-band.
</li>

<li><b>Cauer Filters</b> provide a sharper roll-off still, but at the expense of ripple in both the pass-band and the stop-band, and reduced stop-band attenuation.
</li>

<li><b>Bessel Filters</b> have a phase-shift which is linear with frequency in the pass-band. This corresponds to a pure delay and so Bessel filters preserve the shape of the signal quite well. The roll-off is monotonic and approaches the same slope as the Butterworth and Tschebyschev filters at high frequencies although it has a more gentle roll-off near the corner frequency.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-10-3" class="outline-3">
<h3 id="sec-10-3"><span class="section-number-3">10.3</span> Filter order</h3>
<div class="outline-text-3" id="text-10-3">
<p>
In <a href="http://en.wikipedia.org/wiki/Filter_design">filter design</a> the <b>order</b> of a filter is one characteristic that you might come across. Technically the definition of the filter order is the highest exponent in the <a href="http://en.wikipedia.org/wiki/Z-transform">z-domain</a> (<a href="http://en.wikipedia.org/wiki/Transfer_function">transfer function</a>) of a <a href="http://en.wikipedia.org/wiki/Digital_filter">digital filter</a>. That's helpful isn't it! (not) Another way of describing filter order is the degree of the approximating polynomial for the filter. Yet another way of describing it is that increasing the filter order increases roll-off and brings the filter closer to the ideal response (i.e. a "brick wall" roll-off).
</p>

<p>
Practically speaking, you will find that a second-order butterworth filter provides a nice sharp roll-off without too much undesirable side-effects (e.g. large time lag, ripple in the pass-band, etc).
</p>

<p>
See <a href="http://en.wikipedia.org/wiki/Low-pass_filter#Continuous-time_low-pass_filters">this section</a> of the wikipedia page on low-pass filters for another description.
</p>
</div>
</div>

<div id="outline-container-sec-10-4" class="outline-3">
<h3 id="sec-10-4"><span class="section-number-3">10.4</span> Code for a low-pass Butterworth filter</h3>
<div class="outline-text-3" id="text-10-4">
<p>
Here is a function to implement a second order low-pass butterworth filter in MATLAB:
</p>

<div class="org-src-container">

<pre class="src src-octave"><span style="color: #a020f0;">function</span> data_f <span style="color: #483d8b;">=</span> <span style="color: #0000ff;">lowpass</span>(data<span style="color: #483d8b;">,</span>samprate<span style="color: #483d8b;">,</span>cutoff)
  [B<span style="color: #483d8b;">,</span>A] <span style="color: #483d8b;">=</span> butter(2<span style="color: #483d8b;">,</span>cutoff<span style="color: #483d8b;">/</span>(samprate<span style="color: #483d8b;">/</span>2))<span style="color: #483d8b;">;</span>
  data_f <span style="color: #483d8b;">=</span> filtfilt(B<span style="color: #483d8b;">,</span>A<span style="color: #483d8b;">,</span>data)<span style="color: #483d8b;">;</span>
</pre>
</div>

<p>
Here is one for Python/SciPy:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #a020f0;">from</span> scipy.signal <span style="color: #a020f0;">import</span> butter, filtfilt
<span style="color: #a020f0;">def</span> <span style="color: #0000ff;">lowpass</span>(data,samprate,cutoff):
  <span style="color: #a0522d;">b</span>,<span style="color: #a0522d;">a</span> = butter(2,cutoff/(samprate/2.0),btype=<span style="color: #8b2252;">'low'</span>,analog=0,output=<span style="color: #8b2252;">'ba'</span>)
  <span style="color: #a0522d;">data_f</span> = filtfilt(b,a,data)
  <span style="color: #a020f0;">return</span> data_f
</pre>
</div>

<p>
Here is one for R:
</p>

<div class="org-src-container">

<pre class="src src-r">library(signal)
lowpass &lt;- function(data,samprate,cutoff) {
  bf &lt;- butter(2, cutoff/(samprate/2), type="low")
  data_f &lt;- filtfilt(bf, data)
}
</pre>
</div>

<p>
In all three cases we use a two-pass, bi-directional filter function (called <code>filtfilt()</code> in all three languages) to apply the butterworth filter to the signal. One-way single-pass filter functions (e.g. <code>filter()</code>) introduce time lags. This is why in real-time applications in which you want to filter signals in real time (e.g. to reduce noise) there are time lags introduced.
</p>
</div>
</div>

<div id="outline-container-sec-10-5" class="outline-3">
<h3 id="sec-10-5"><span class="section-number-3">10.5</span> Application: high-frequency noise and taking derivatives</h3>
<div class="outline-text-3" id="text-10-5">
<p>
One of the characteristics of just about any experimental measurement
is that the signal that you measure with your instrument will contain
a combination of true signal and "noise" (random variations in the
signal). A common approach is to take many measurements and average them together. This is what is commonly done in EEG/ERP studies, in EMG studies, with spike-triggered averaging, and many others. The idea is that if the "real" part of the signal is constant over trials, and the "noise" part of the signal is random from trial to trial, then averaging over many trials will average out the noise (which is sometimes positive, sometimes negative, but on balance, zero) and what remains will be the true signal.
</p>

<p>
You can imagine however that there are downsides to this approach. First of all, it requires that many, many measures be taken so that averages can be computed. Second, there is no guarantee that the underlying "true" signal will in fact remain constant over those many measurements. Third, one cannot easily do analyses on single trials, since we have to wait for the average before we can look at the data.
</p>

<p>
One solution is to use signal processing techniques such as <b>filtering</b> to separate the noise from the signal. A limitation of this technique however is that when we apply a filter (for example a low-pass filter), we filter out <b>all</b> power in the signal above the cutoff frequency &#x2014; whether "real" signal or noise. This approach thus assumes that we are fairly certain that the power above our cutoff is of no interest to us.
</p>

<p>
One salient reason to low-pass filter a signal, and remove high-frequency noise, is for cases in which we are interested in taking the temporal derivative of a signal. For example, let's say we have recorded the position of the fingertip as a subject reaches from a start position on a tabletop, to a target located in front of them on a computer screen. Using a device like Optotrak we can record the (x,y,z) coordinates of the fingertip at a sampling rate of 200 Hz. Here is an example of such a recording:
</p>


<div class="figure">
<p><img src="code/signal_optotrak.jpg" alt="signal_optotrak.jpg" height="600" />
</p>
</div>

<p>
The top panel shows position in one coordinate over time. The middle panel shows the result of taking the derivative of the position signal to obtain velocity. I have simply used the <code>diff()</code> function here to obtain a numerical estimate of the derivative, taking the forward difference. Note how much noisier it looks than the position signal. Finally the bottom panel shows the result of taking the derivative of the velocity signal, to obtain acceleration. It is so noisy one cannot even see the peaks in the acceleration signal, they are completely masked by noise.
</p>

<p>
What is happening here is that small amounts of noise in the position
signal are amplified each time a derivative is taken. One solution is
to <b>low-pass filter</b> the position signal. The choice of the cutoff
frequency is key &#x2014; too low and we will decimate the signal itself,
and too high and we will not remove enough of the high frequency
noise. It happens that we are fairly certain in this case that there
isn't much real signal power above 12 Hz for arm movements. Here is
what it looks like when we low-pass filter the position signal at a
12Hz cutoff frequency:
</p>


<div class="figure">
<p><img src="code/signal_optotrak_filtered.jpg" alt="signal_optotrak_filtered.jpg" height="600" />
</p>
</div>

<p>
What you can see is that for the position over time, the filtered
version (shown in red) doesn't differ that much, at least not visibly,
from the unfiltered version (in blue). The velocity and acceleration
traces however look vastly different. Differentiating the filtered
position signal yields a velocity trace (shown in red in the middle
panel) that is way less noisy than the original version. Taking the
derivative again of this new velocity signal yields an acceleration
signal (shown in red in the bottom panel) that is actually usable. The
original version (shown in blue) is so noisy it overwhelms the entire
panel. Note the scale change on the ordinate.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-11" class="outline-2">
<h2 id="sec-11"><span class="section-number-2">11</span> Quantization</h2>
<div class="outline-text-2" id="text-11">
<p>
Converting an analog signal to a digital form involves the
quantization of the analog signal. In this procedure the range of the
input variable is divided into a set of class intervals. Quantization
involves the replacement of each value of the input variable by the
nearest class interval centre.
</p>

<p>
Another way of saying this is that when sampling an analog signal and converting it to digital values, one is limited by the precision with which one can represent the (analog) signal digitally. Usually a piece of hardware called an analog-to-digital (A/D) board is the thing that performs this conversion. The range of A/D boards are usually specified in terms of <b>bits</b>. For example a 12-bit A/D board is capable of specifying \(2^{12}=4096\) unique values. This means that a continuous signal will be represented using only 4096 possible values. A 16-bit A/D board would be capable of using \(2^{16}=65,536\) different values. Obviously the higher the better, in terms of the resolution of the underlying digital representation. Often however in practice, higher resolutions come at the expense of lower sampling rates.
</p>

<p>
As an example, let's look at a continuous signal and its digital representation using a variety of (low) sample resolutions:
</p>


<div class="figure">
<p><img src="code/signal_quantization.jpg" alt="signal_quantization.jpg" height="600" />
</p>
</div>

<p>
Here we see as the number of possible unique values increases, the digital representation of the underlying continuous signal gets more and more accurate. Also notice that in general, quantization adds noise to the representation of the signal.
</p>

<p>
It is also important to consider the amplitude of the sampled signal compared to the range of the A/D board. In other words, if the signal you are sampling has a very small amplitude compared to the range of the A/D board then essentially your sample will only be occupying a small subset of the total possible values dictated by the resolution of the A/D board, and the effects of quantization will be greatly increased.
</p>

<p>
For example, let's say you are using an A/D board with 12 bits of resolution and an input range of +/- 5 Volts. This means that you have \(2^{12}=4096\) possible values with which to characterize a signal that ranges maximally over 10 Volts. If your signal is very small compared to this range, e.g. if it only occupies 25 millivolts, then the A/D board is only capable of using \(0.0025/10*4096 = 10\) (ten) unique values to characterize your signal! The resulting digitized characterization of your signal will not be very smooth.
</p>

<p>
Whenever possible, amplify your signal to occupy the maximum range of the A/D board you're using. Of course the trick is always to amplify the signal without also amplifying the noise!
</p>
</div>
</div>

<div id="outline-container-sec-12" class="outline-2">
<h2 id="sec-12"><span class="section-number-2">12</span> Sources of noise</h2>
<div class="outline-text-2" id="text-12">
<p>
It is useful to list a number of common sources of noise in physiological
signals:
</p>

<ul class="org-ul">
<li><b>Extraneous Signal Noise</b> arises when a recording device records more than one signal &#x2014; i.e. signals in addition to the one you as an experimenter are interested in. It's up to you to decide which is signal and which is noise. For example, electrodes placed on the chest will record both ECG and EMG activity from respiratory muscles. A cardiologist might consider the ECG signal and EMG noise, while a respiratory physiologist might consider the EMG signal and the ECG noise.
</li>

<li><b>1/f Noise</b>: Devices with a DC response sometimes show a low frequency trend appearing on their output even though the inputs don't change. EEG systems and EOG systems often show this behaviour. Fourier analyses show that the amplitude of this noise increases as frequency decreases.
</li>

<li><b>Power or 60 Hz Noise</b> is interference from 60 Hz AC electrical power signals. This is one of the most common noise sources that experimental neurophysiologists have to deal with. Often we find, for example, on hot days when the air conditioning in the building is running, we see much more 60 Hz noise in our EMG signals than on other days. Some neurophysiologists like to do their recordings late at night or on weekends when there is minimal activity on the electrical system in their building.
</li>

<li><b>Thermal Noise</b> arises from the thermal motion of electrons in conductors, is always present and determines the theoretical minimum noise levels for a device. Thermal noise is white (has a Gaussian probability distribution) and thus has a flat frequency content &#x2014; equal power across all frequencies.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-13" class="outline-2">
<h2 id="sec-13"><span class="section-number-2">13</span> Exercises</h2>
<div class="outline-text-2" id="text-13">
<ul class="org-ul">
<li><a href="exercises.html">Exercises</a> 31 through 36 will get you doing some signal processing.
</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr />Paul Gribble | fall 2014<br>This <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" rel="dct:type">work</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a><br><a rel="license"href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by/4.0/80x15.png" /></a><br />
</div>
</body>
</html>
